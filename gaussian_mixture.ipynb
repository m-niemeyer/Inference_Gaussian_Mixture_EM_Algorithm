{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model and the EM Algorithm\n",
    "\n",
    "This script shows how the *Expectation-Maximaisation (EM) Algorithm* can be used to recover the means and covariance matrices from data which is assumed to be generated by a Gaussian-mixture model. \n",
    "\n",
    "## Core Problem\n",
    "\n",
    "The core of problem is that we observe data points $x_i$, but we are not given from which Gaussian they came from. We assume that the data arose from a Gaussian-mixture model, and by using the EM Algorithm, we are able to give predictions for the means of the Gaussians, the mixing coefficients, and the covariance matrices. Thus, the only parameter that we set is the number of Gaussians $k$ which is why the EM algorithm is an example of *unsupervised learning*. We could extend our model to its hierarchical version to infer $k$ itself from the data. However, this is not part of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixing_coefficients(number):\n",
    "    a = 1\n",
    "    pi_v = np.zeros(number)\n",
    "    for i in range(number-1):\n",
    "        pi_v[i] = np.random.uniform(0, a)\n",
    "        a = a - pi_v[i]\n",
    "    pi_v[number-1] = a\n",
    "    return pi_v\n",
    "\n",
    "num_gaussian = 7\n",
    "pi_v = generate_mixing_coefficients(num_gaussian)\n",
    "sigma_v = np.zeros((num_gaussian,2,2))\n",
    "sigma_v[:, 0, 0] = np.random.uniform(1, 4, size=num_gaussian)\n",
    "sigma_v[:, 1, 1] = np.random.uniform(1, 4, size=num_gaussian)\n",
    "sigma_v[:, 0, 1] = np.random.normal(0, 1, size=num_gaussian)\n",
    "sigma_v[:, 1, 0] = sigma_v[:, 0, 1]\n",
    "\n",
    "mean_v = np.random.uniform(-15, 15, size=(num_gaussian, 2))\n",
    "\n",
    "#samples = np.random.multivariate_normal(mean_v[0], sigma_v[0], size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can draw samples from the mixture of Gaussians by executing the following procedure for each sample:\n",
    "1. Draw $\\pi_k$ from the Categorical distribution conditioned on the vector $\\mathbf{\\pi_v}$ which are the mixing coefficients\n",
    "2. Draw a sample x from the k-th Gaussian, $x \\sim \\mathcal{N}(\\mu_k,\\,\\Sigma_k)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "samples = np.zeros((num_samples, 2))\n",
    "p = np.random.multinomial(num_samples, pi_v)\n",
    "samples[:p[0],:] = np.random.multivariate_normal(mean_v[0], sigma_v[0], size=p[0])\n",
    "for i in range(1, num_gaussian, 1):\n",
    "    samples[np.sum(p[:i]):np.sum(p[:i+1]),:] = np.random.multivariate_normal(mean_v[i], sigma_v[i], size=p[i])\n",
    "plt.scatter(samples[:, 0], samples[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM Algorithm\n",
    "\n",
    "We only use our set of samples and use the EM algorithm to recover the mixing coefficients, covariance matrices, and means of the set of Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we initialise the values\n",
    "mean_em = samples[np.random.randint(low=0, high=num_samples, size=num_gaussian),:]\n",
    "sigma_em = np.array([np.identity(2)]*num_gaussian)\n",
    "pi_em = np.zeros(num_gaussian)\n",
    "a = 1\n",
    "for i in range(num_gaussian-1):\n",
    "    pi_em[i] = np.random.uniform(0, a)\n",
    "    a -= pi_em[i]\n",
    "pi_em[num_gaussian-1] = a\n",
    "gamma = np.zeros((num_samples, num_gaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelyhood(x, mean_em, sigma_em, pi_em):\n",
    "    s = np.sum([np.log(np.sum([pi_em[k]*multivariate_normal.pdf(x_i, mean=mean_em[k,:], cov=sigma_em[k,:,:]) for k in range(num_gaussian)])) for x_i in x])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo = 1\n",
    "log_l = np.array([log_likelyhood(samples, mean_em, sigma_em, pi_em)])\n",
    "dif = 100\n",
    "while (dif > 1 or epo>30):\n",
    "    # E step\n",
    "    for n in range(num_samples):\n",
    "        s = np.sum([pi_em[k]*multivariate_normal.pdf(samples[n,:], mean=mean_em[k,:], cov=sigma_em[k,:,:]) for k in range(num_gaussian)])\n",
    "        for k in range(num_gaussian):\n",
    "            gamma[n, k] = pi_em[k]*multivariate_normal.pdf(samples[n,:], mean=mean_em[k,:], cov=sigma_em[k,:,:])/s\n",
    "            \n",
    "    # M Step\n",
    "    N_k = [np.sum([gamma[n, k] for n in range(num_samples)]) for k in range(num_gaussian)]\n",
    "    mean_em = np.array([np.sum([gamma[n, k]*samples[n,:] for n in range(num_samples)], axis=0)/N_k[k] for k in range(num_gaussian)])\n",
    "    sigma_em = np.array([np.sum([gamma[n,k]*np.outer(samples[n,:]-mean_em[k,:], samples[n,:]-mean_em[k,:]) for n in range(num_samples)], axis=0)/N_k[k] for k in range(num_gaussian)])\n",
    "    pi_em = np.array([N_k[k]/num_samples for k in range(num_gaussian)])\n",
    "    \n",
    "    # Check Convergence criterium\n",
    "    log_l = np.append(log_l, log_likelyhood(samples, mean_em, sigma_em, pi_em))\n",
    "    dif = log_l[len(log_l)-1] - log_l[-2:-1]\n",
    "    print(\"Run\", epo, 'done with log likelyhood:', log_l[len(log_l)-1])\n",
    "    epo += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's have a look at the means that the EM-algorithm recovered (in red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(samples[:,0],samples[:,1],color='blue')\n",
    "plt.scatter(mean_em[:,0], mean_em[:,1],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
